{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "Current base path: C:\\Users\\Stefan\\Dropbox\\Masterarbeit\n"
     ]
    }
   ],
   "source": [
    "%pylab tk\n",
    "\n",
    "import numpy as np\n",
    "import mahotas as mh\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "from time import time\n",
    "from math import radians\n",
    "from skimage import io, color, img_as_float, img_as_ubyte\n",
    "from skimage.transform import rescale\n",
    "from skimage.util import pad\n",
    "from IPython.parallel import Client\n",
    "from sklearn.decomposition import PCA, RandomizedPCA\n",
    "from scipy.cluster.vq import kmeans2\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import helpers.features as fh\n",
    "import helpers.display as dh\n",
    "\n",
    "BASE_PATH = os.getcwd()\n",
    "print(\"Current base path: {0}\".format(BASE_PATH))\n",
    "DATA_PATH = BASE_PATH + '/Daten/2D/Talus_dorsal_cut_2/'\n",
    "TO_PATH = BASE_PATH + '/Daten/2D/Talus_dorsal_outlined/'\n",
    "TEST_FILES = json.loads(open(BASE_PATH + '/Daten/2D/testfiles.json').read())\n",
    "\n",
    "NUMBER_OF_SECTIONS = 150\n",
    "FEATURE_FN = mh.features.pftas\n",
    "FEATURE_FN_2 = mh.features.haralick\n",
    "\n",
    "def split(image):\n",
    "    return numpy.array_split(image, NUMBER_OF_SECTIONS, axis=1)\n",
    "\n",
    "def join(images):\n",
    "    return numpy.concatenate(images, axis=1)\n",
    "\n",
    "def extract_windows(image):\n",
    "    split_y = numpy.array_split(image, NUMBER_OF_SECTIONS, axis=0) \n",
    "    \n",
    "    return list(map(split, split_y))\n",
    "\n",
    "def extract_features(windows, image):\n",
    "    features = []\n",
    "    for windows_x in windows:\n",
    "        for window in windows_x:\n",
    "            f1 = FEATURE_FN(window).flatten()\n",
    "            #f2 = FEATURE_FN_2(window).flatten()\n",
    "            #features.append(np.concatenate((f1, f2)))\n",
    "            features.append(f1)\n",
    "    return np.array(features)\n",
    "\n",
    "def extract_features_full_img(windows, image):\n",
    "    features = []\n",
    "    for windows_x in windows:\n",
    "        f_x = []\n",
    "        for window in windows_x:\n",
    "            f_x.append(np.full((window.shape[0], window.shape[1], 169), FEATURE_FN(window).flatten()))\n",
    "        features.append(f_x)\n",
    "        \n",
    "    features = list(map(join, features))\n",
    "        \n",
    "    return np.concatenate(features).reshape((image.shape[0] * image.shape[1], 169))\n",
    "\n",
    "def calculate_distance_for_single_image(image):\n",
    "    windows = extract_windows(image)\n",
    "    features = extract_features(windows, image)\n",
    "    return fh.normalize_each(features)\n",
    "\n",
    "def append_locality(features):\n",
    "    x = np.tile(np.arange(NUMBER_OF_SECTIONS) + 1, NUMBER_OF_SECTIONS)\n",
    "    y = np.repeat(np.arange(NUMBER_OF_SECTIONS) + 1, NUMBER_OF_SECTIONS)\n",
    "    locality = np.divide(np.array([ x, y ]).transpose(), float(NUMBER_OF_SECTIONS))\n",
    "    \n",
    "    return np.concatenate((features, locality), axis=1)\n",
    "\n",
    "def do_clustering(image, features):\n",
    "    #db = DBSCAN(eps=0.3, min_samples=25).fit(features)\n",
    "    #labels = db.labels_\n",
    "    centroids, labels = kmeans2(features, 4)\n",
    "    return labels.reshape((image.shape[0], image.shape[1]))\n",
    "    \n",
    "def reduce_feature_complexity(features):\n",
    "    pca = PCA(n_components=6)\n",
    "    #pca = RandomizedPCA(n_components=10)\n",
    "    reduced = pca.fit_transform(features)\n",
    "    return reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file = TEST_FILES[2]\n",
    "rgb_image = io.imread(DATA_PATH + file['filename'])\n",
    "fake_img = np.zeros((NUMBER_OF_SECTIONS, NUMBER_OF_SECTIONS, 3))\n",
    "\n",
    "features = calculate_distance_for_single_image(rgb_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dh.features(plt, np.zeros((NUMBER_OF_SECTIONS, NUMBER_OF_SECTIONS, 3)), features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reduced = reduce_feature_complexity(features)\n",
    "reduced = append_locality(reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reduced' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-afc5a1169f9b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNUMBER_OF_SECTIONS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNUMBER_OF_SECTIONS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduced\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'reduced' is not defined"
     ]
    }
   ],
   "source": [
    "dh.features(plt, np.zeros((NUMBER_OF_SECTIONS, NUMBER_OF_SECTIONS, 3)), reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do_clustering: 0.028960943222s\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "labels = do_clustering(np.zeros((NUMBER_OF_SECTIONS, NUMBER_OF_SECTIONS, 3)), reduced)\n",
    "print('do_clustering: {0}s'.format(time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
