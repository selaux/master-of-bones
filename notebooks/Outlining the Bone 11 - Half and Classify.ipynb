{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "Current base path: C:\\Users\\Stefan\\Dropbox\\Masterarbeit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['radians', 'pad']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    }
   ],
   "source": [
    "%pylab qt\n",
    "\n",
    "import numpy as np\n",
    "import mahotas as mh\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import itertools\n",
    "from time import time\n",
    "from math import radians\n",
    "from skimage import io, color, img_as_float, img_as_ubyte\n",
    "from skimage.transform import rescale\n",
    "from skimage.util import pad\n",
    "from IPython.parallel import Client\n",
    "from skimage.measure import label as sklabel\n",
    "from sklearn.decomposition import PCA, RandomizedPCA\n",
    "from scipy.cluster.vq import kmeans2\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.svm import SVC\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "import helpers.features as fh\n",
    "import helpers.display as dh\n",
    "\n",
    "BASE_PATH = os.getcwd()\n",
    "print(\"Current base path: {0}\".format(BASE_PATH))\n",
    "DATA_PATH = BASE_PATH + '/Daten/2D/Talus_dorsal_cut_2/'\n",
    "TO_PATH = BASE_PATH + '/Daten/2D/Talus_dorsal_outlined/'\n",
    "TEST_FILES = json.loads(open(BASE_PATH + '/Daten/2D/testfiles.json').read())\n",
    "\n",
    "MIN_SIZE = 10\n",
    "REQUIRED_DIFFERENCE_TO_SPLIT = 0.3\n",
    "FEATURE_FN = mh.features.pftas\n",
    "\n",
    "def do_split(image, partition, force):\n",
    "    rect = partition['rect']\n",
    "    current_features = partition['features']\n",
    "    split_y = rect[0] + int((rect[1] - rect[0]) / 2)\n",
    "    split_x = rect[2] + int((rect[3] - rect[2]) / 2)\n",
    "    partition_size = (rect[1] - rect[0]) * (rect[3] - rect[2]) / 4\n",
    "    possible_partitions = (\n",
    "        {\n",
    "            'rect': [rect[0], split_y, rect[2], split_x],\n",
    "            'features': FEATURE_FN(image[rect[0]:split_y, rect[2]:split_x, :]).flatten()\n",
    "        },\n",
    "        {\n",
    "            'rect': [split_y, rect[1], rect[2], split_x],\n",
    "            'features': FEATURE_FN(image[split_y:rect[1], rect[2]:split_x, :]).flatten()\n",
    "        },\n",
    "        {\n",
    "            'rect': [rect[0], split_y, split_x, rect[3]],\n",
    "            'features': FEATURE_FN(image[rect[0]:split_y, split_x:rect[3], :]).flatten()\n",
    "        },\n",
    "        {\n",
    "            'rect': [split_y, rect[1], split_x, rect[3]],\n",
    "            'features': FEATURE_FN(image[split_y:rect[1], split_x:rect[3], :]).flatten()\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    if force:\n",
    "        return possible_partitions\n",
    "    if rect[1] - split_y < MIN_SIZE or split_y-rect[0] < MIN_SIZE:\n",
    "        return None\n",
    "    if rect[3] - split_x < MIN_SIZE or split_x-rect[2] < MIN_SIZE:\n",
    "        return None\n",
    "    \n",
    "    combinations = itertools.combinations(possible_partitions, 2)\n",
    "    distances = [ np.linalg.norm(a['features'] - b['features']) for a, b in combinations ]\n",
    "    #print(distances)\n",
    "    #asd = asdf\n",
    "    if max(distances) > REQUIRED_DIFFERENCE_TO_SPLIT:\n",
    "        return possible_partitions\n",
    "    \n",
    "    return None\n",
    "\n",
    "def extract_partitions(image):\n",
    "    partitions = [\n",
    "        {\n",
    "            'rect': np.array([ 0, image.shape[0], 0, image.shape[1] ]),\n",
    "            'features': FEATURE_FN(image).flatten()\n",
    "        }\n",
    "    ]\n",
    "    i = 0\n",
    "    finished_partitions = []\n",
    "    \n",
    "    while len(partitions) != 0:\n",
    "        partition = partitions.pop(0)\n",
    "        \n",
    "        split = do_split(image, partition, i <= 21)\n",
    "        i += 1\n",
    "        if split:\n",
    "            partitions += split\n",
    "        else:\n",
    "            finished_partitions.append(partition)\n",
    "    return finished_partitions\n",
    "\n",
    "def append_locality(features, partitions, rgb_image):\n",
    "    locality = np.zeros((features.shape[0], 2))\n",
    "    print(features.shape[0])\n",
    "    print(locality.shape)\n",
    "    for i, p in enumerate(partitions):\n",
    "        rect = p['rect']\n",
    "        center_y = (rect[0] + (rect[1] - rect[0]) / 2.0) / rgb_image.shape[0]\n",
    "        center_x = (rect[2] + (rect[3] - rect[2]) / 2.0) / rgb_image.shape[1]\n",
    "        \n",
    "        locality[i, :] = center_y, center_x\n",
    "       \n",
    "    return np.concatenate((features, locality), axis=1)\n",
    "\n",
    "def do_clustering(features):\n",
    "    #db = DBSCAN(eps=0.3, min_samples=25).fit(features)\n",
    "    #labels = db.labels_\n",
    "    centroids, labels = kmeans2(features, 5, iter=25)\n",
    "    return labels\n",
    "    \n",
    "def reduce_feature_complexity(features):\n",
    "    pca = PCA(n_components=6)\n",
    "    #pca = RandomizedPCA(n_components=10)\n",
    "    reduced = pca.fit_transform(features)\n",
    "    return reduced\n",
    "\n",
    "def get_bone_clusters(partitions):\n",
    "    partition_centers = np.zeros((len(partitions), 2))\n",
    "    partition_labels = np.array([ p['label'] for p in partitions ])\n",
    "    labels = np.array(range(partition_labels.min(), partition_labels.max()+1))\n",
    "    centroids = np.zeros((labels.shape[0], 2))\n",
    "    print(labels)\n",
    "    \n",
    "    for l in labels:\n",
    "        indices = np.argwhere(partition_labels == l)\n",
    "        num_indices = float(indices.shape[0])\n",
    "        for i in indices:\n",
    "            rect = partitions[i]['rect']\n",
    "            partition_centers[i, :] = [rect[0] + (rect[1] - rect[0]) / 2.0, rect[2] + (rect[3] - rect[2]) / 2.0]\n",
    "            centroids[l, :] = centroids[l, :] + partition_centers[i, :] / num_indices\n",
    "        \n",
    "    mean_distance_from_centroids = np.zeros((labels.shape[0]))\n",
    "    for l in labels:\n",
    "        centers = partition_centers[partition_labels == l, :]\n",
    "        num_partitions_in_cluster = centers.shape[0]\n",
    "        to_centroid = centers - np.tile(centroids[l, :], (num_partitions_in_cluster, 1))\n",
    "        mean_distance_from_centroids[l] = np.mean(np.linalg.norm(to_centroid, axis=1))\n",
    "        \n",
    "    print(mean_distance_from_centroids)\n",
    "    dist_centroids, dist_labels = kmeans2(mean_distance_from_centroids, 2, iter=25)\n",
    "    bone_clusters = labels[dist_labels == np.argmin(dist_centroids)]\n",
    "    \n",
    "    return bone_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2896\n"
     ]
    }
   ],
   "source": [
    "file = TEST_FILES[3]\n",
    "rgb_image = io.imread(DATA_PATH + file['filename'])\n",
    "\n",
    "partitions = extract_partitions(rgb_image)\n",
    "print(len(partitions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots()\n",
    "axes.imshow(rgb_image)\n",
    "for partition in partitions:\n",
    "    rect = partition['rect']\n",
    "    axes.add_patch(Rectangle((rect[2], rect[0]), rect[3] - rect[2], rect[1]-rect[0], fill=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reduced = reduce_feature_complexity(np.array([ p['features'] for p in partitions ]))\n",
    "#reduced = append_locality(reduced, partitions, rgb_image)\n",
    "\n",
    "reduced_length = reduced.shape[1]\n",
    "reduced_image = np.zeros((rgb_image.shape[0], rgb_image.shape[1], reduced_length))\n",
    "for i, p in enumerate(partitions):\n",
    "    rect = p['rect']\n",
    "    features = reduced[i, :]\n",
    "    reduced_image[rect[0]:rect[1], rect[2]:rect[3], :] = features\n",
    "reduced_image = reduced_image.reshape((reduced_image.shape[0] * reduced_image.shape[1], reduced_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dh.features(plt, rgb_image, reduced_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do_clustering: 0.0s\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "labels = do_clustering(reduced)\n",
    "for i, l in enumerate(labels):\n",
    "    partitions[i]['label'] = l\n",
    "print('do_clustering: {0}s'.format(time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_image = np.zeros((rgb_image.shape[0], rgb_image.shape[1]))\n",
    "for p in partitions:\n",
    "    rect = p['rect']\n",
    "    label_image[rect[0]:rect[1], rect[2]:rect[3]] = p['label']\n",
    "dh.clusters(plt, rgb_image, label_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n",
      "[ 422.98861412  589.31007708  411.2609151   463.85217438  577.1389891 ]\n"
     ]
    }
   ],
   "source": [
    "bone_clusters = get_bone_clusters(partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_image = np.zeros((rgb_image.shape[0], rgb_image.shape[1]))\n",
    "for p in partitions:\n",
    "    rect = p['rect']\n",
    "    if p['label'] in bone_clusters:\n",
    "        label_image[rect[0]:rect[1], rect[2]:rect[3]] = 1\n",
    "label_image = sklabel(label_image, 4)\n",
    "dh.clusters(plt, rgb_image, label_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
