{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "Current base path: /home/stefan/Dropbox/Masterarbeit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['f', 'radians', 'degrees', 'normalize']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    }
   ],
   "source": [
    "%pylab qt\n",
    "\n",
    "import os\n",
    "import itertools\n",
    "import gzip\n",
    "import cPickle as pickle\n",
    "import cv2\n",
    "import numpy as np\n",
    "from math import radians, degrees\n",
    "from glob import glob\n",
    "from scipy.signal import argrelextrema\n",
    "from sklearn.preprocessing import normalize\n",
    "from skimage.transform import estimate_transform\n",
    "from scipy.interpolate import splprep, splev\n",
    "\n",
    "import helpers.classes as ch\n",
    "import helpers.features as fh\n",
    "import helpers.display as dh\n",
    "import helpers.geometry as gh\n",
    "reload(ch)\n",
    "reload(fh)\n",
    "reload(dh)\n",
    "reload(gh)\n",
    "\n",
    "BASE_PATH = os.getcwd()\n",
    "print(\"Current base path: {0}\".format(BASE_PATH))\n",
    "DATA_PATH = BASE_PATH + '/Daten/2D/Talus_dorsal_mesh_2/'\n",
    "TO_PATH = BASE_PATH + '/Daten/2D/Talus_dorsal_filtered_and_registered_outline/'\n",
    "NUM_SPLINE_POINTS = 100\n",
    "\n",
    "def extract_landmark_points(outline_points, outline_edges):\n",
    "    step_size = 1\n",
    "    landmark_definitions = [\n",
    "        {\n",
    "            'a_min': 30,\n",
    "            'a_max': 90,\n",
    "            'method': 'max'\n",
    "        },\n",
    "        {\n",
    "            'a_min': 80,\n",
    "            'a_max': 100,\n",
    "            'method': 'min'\n",
    "        },\n",
    "        {\n",
    "            'a_min': 90,\n",
    "            'a_max': 150,\n",
    "            'method': 'max'\n",
    "        },\n",
    "        {\n",
    "            'a_min': 160,\n",
    "            'a_max': 200,\n",
    "            'method': 'max'\n",
    "        },\n",
    "        {\n",
    "            'a_min': 210,\n",
    "            'a_max': 270,\n",
    "            'method': 'max'\n",
    "        },\n",
    "        {\n",
    "            'a_min': 260,\n",
    "            'a_max': 280,\n",
    "            'method': 'min'\n",
    "        },\n",
    "        {\n",
    "            'a_min': 270,\n",
    "            'a_max': 330,\n",
    "            'method': 'max'\n",
    "        }\n",
    "    ]\n",
    "    landmarks = []\n",
    "    rho = 2\n",
    "    centroid = mean(outline_points, axis=0)\n",
    "    \n",
    "    for definition in landmark_definitions:\n",
    "        intersects_for_angles = []\n",
    "        method = np.argmax if definition['method'] == 'max' else np.argmin\n",
    "        \n",
    "        for angle in range(definition['a_min'], definition['a_max']):\n",
    "            startpoint = centroid\n",
    "            endpoint = gh.pol2cart(rho, radians(angle)) + centroid\n",
    "            \n",
    "            intersect = None\n",
    "            for edge in outline_edges:\n",
    "                p1 = outline_points[edge[0], :]\n",
    "                p2 = outline_points[edge[1], :]\n",
    "                \n",
    "                intersect = gh.seg_intersect(p1, p2, startpoint, endpoint)\n",
    "                if intersect is not None:\n",
    "                    break\n",
    "            if intersect is None:\n",
    "                raise Exception('No Intersect.')\n",
    "            else:\n",
    "                intersects_for_angles.append(intersect)\n",
    "        \n",
    "        intersects_for_angles = np.array(intersects_for_angles)\n",
    "        distances = np.linalg.norm(intersects_for_angles - np.tile(centroid, (intersects_for_angles.shape[0], 1)), axis=1)\n",
    "        \n",
    "        landmarks.append(intersects_for_angles[method(distances), :])\n",
    "        \n",
    "    return np.array(landmarks)\n",
    "\n",
    "def register_outline_with_icp(reference, reference_edges, points, edges, no_iterations = 1):\n",
    "    landmarks_reference = extract_landmark_points(reference, reference_edges)\n",
    "\n",
    "    for i in range(no_iterations):\n",
    "        landmarks = extract_landmark_points(points, edges)\n",
    "        #Compute the transformation between the current source\n",
    "        #and destination cloudpoint\n",
    "        #tform = estimate_transform('affine', landmarks, landmarks_reference)\n",
    "        #points = tform(points)\n",
    "        \n",
    "        R, t = gh.estimate_rigid_transform(landmarks, landmarks_reference)\n",
    "        R = np.array(R)\n",
    "        t = np.array(t)\n",
    "        #Transform the previous source and update the\n",
    "        #current source cloudpoint\n",
    "        points = (np.dot(R, points.transpose())).transpose() + np.tile(t, (points.shape[0], 1))\n",
    "    \n",
    "    return points\n",
    "\n",
    "def extract_spline(points):\n",
    "    y = points[:,0].flatten()\n",
    "    x = points[:,1].flatten()\n",
    "    \n",
    "    tck, u = splprep([y, x], s=0)\n",
    "    coords = splev(np.linspace(0, 1, NUM_SPLINE_POINTS), tck)\n",
    "    \n",
    "    spline_points = np.zeros((NUM_SPLINE_POINTS, 2))\n",
    "    spline_points[:, 0] = coords[0]\n",
    "    spline_points[:, 1] = coords[1]\n",
    "    \n",
    "    return spline_points\n",
    "\n",
    "def do_registration(loaded):\n",
    "    transposed_and_scaled = []\n",
    "    registered = []\n",
    "    \n",
    "    for outline in loaded:\n",
    "        points = outline['points']\n",
    "        \n",
    "        spl_points = extract_spline(points)\n",
    "        centroid = mean(spl_points, axis=0)\n",
    "        points = points - np.tile(centroid, (len(points), 1))\n",
    "        spl_points = spl_points - np.tile(centroid, (len(spl_points), 1))\n",
    "        \n",
    "        #scale = sqrt(np.sum(np.power(spl_points[:, 0], 2)) / len(spl_points))\n",
    "        scale = sqrt(np.sum(np.power(spl_points, 2)) / len(spl_points))\n",
    "        points = np.divide(points, scale)\n",
    "        points, edges = gh.normalize_outline(points, outline['edges'])\n",
    "        \n",
    "        transposed_and_scaled.append({\n",
    "            'label': outline['label'],\n",
    "            'filename': outline['filename'],\n",
    "            'class': outline['class'],\n",
    "            'class_label': outline['class_label'],\n",
    "            'points': points,\n",
    "            'edges': edges\n",
    "        })\n",
    "    \n",
    "    reference = max(transposed_and_scaled, key=lambda o: o['points'].shape[0])\n",
    "    for outline in transposed_and_scaled:\n",
    "        points = outline['points']\n",
    "        edges = outline['edges']\n",
    "        \n",
    "        if not np.array_equal(points, reference):\n",
    "            points = register_outline_with_icp(reference['points'], reference['edges'], points, outline['edges'])\n",
    "            points, edges = gh.normalize_outline(points, edges)\n",
    "        registered.append({\n",
    "            'label': outline['label'],\n",
    "            'filename': outline['filename'],\n",
    "            'class': outline['class'],\n",
    "            'class_label': outline['class_label'],\n",
    "            'points': points,\n",
    "            'edges': edges\n",
    "        })\n",
    "    \n",
    "    return registered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filenames = glob(DATA_PATH + '*.pkl')\n",
    "loaded = []\n",
    "for filename in filenames:\n",
    "    with gzip.GzipFile(filename, 'rb') as f:\n",
    "        content = pickle.load(f)\n",
    "        \n",
    "    if 'done' in content and content['done']:\n",
    "        basename = os.path.basename(filename)\n",
    "        points = content['points']\n",
    "        triangles = content['simplices']\n",
    "\n",
    "        label = ''.join([i if ord(i) < 128 else ' ' for i in basename])\n",
    "\n",
    "        cls = ch.get_class(basename)\n",
    "\n",
    "        outline_points, outline_edges = gh.extract_outline(points, triangles)\n",
    "\n",
    "        loaded.append({\n",
    "            'label': label,\n",
    "            'filename': basename,\n",
    "            'class': cls[0],\n",
    "            'class_label': cls[1],\n",
    "            'points': outline_points,\n",
    "            'edges': outline_edges\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered = ch.filter_by_classes(loaded, [ 2 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<helpers.windows.VTKWindow at 0x7f29c7c4ca68>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dh.outlines(filtered, color_by_class=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "registered = do_registration(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<helpers.windows.VTKWindow at 0x7fe431514770>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dh.outlines(registered, color_by_class=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outline = registered[5]\n",
    "landmarks = extract_landmark_points(outline['points'], outline['edges'])\n",
    "window = dh.outline(outline, show_direction=True)\n",
    "pointActor = dh.get_points_actor(landmarks)\n",
    "window.ren.AddActor(pointActor)\n",
    "window.vtkWidget.GetRenderWindow().Render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for outline in registered:\n",
    "    basename = os.path.basename(outline['filename'])\n",
    "    destination = os.path.join(TO_PATH, basename)\n",
    "    \n",
    "    np.savez(destination, points=outline['points'], edges=outline['edges'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
