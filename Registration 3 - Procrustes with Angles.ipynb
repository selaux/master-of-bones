{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "Current base path: C:\\Users\\Stefan\\Dropbox\\Masterarbeit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['radians', 'degrees', 'normalize']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    }
   ],
   "source": [
    "%pylab qt\n",
    "\n",
    "import os\n",
    "import itertools\n",
    "import cv2\n",
    "import numpy as np\n",
    "from math import radians, degrees\n",
    "from glob import glob\n",
    "from scipy.signal import argrelextrema\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import helpers.features as fh\n",
    "import helpers.display as dh\n",
    "import helpers.geometry as gh\n",
    "reload(fh)\n",
    "reload(dh)\n",
    "reload(gh)\n",
    "\n",
    "BASE_PATH = os.getcwd()\n",
    "print(\"Current base path: {0}\".format(BASE_PATH))\n",
    "DATA_PATH = BASE_PATH + '/Daten/2D/Talus_dorsal_mesh/'\n",
    "TO_PATH = BASE_PATH + '/Daten/2D/Talus_dorsal_registered_outline/'\n",
    "\n",
    "def extract_landmark_points(outline_points, outline_edges):\n",
    "    step_size = 1\n",
    "    landmark_definitions = [\n",
    "        {\n",
    "            'a_min': 30,\n",
    "            'a_max': 90,\n",
    "            'method': 'max'\n",
    "        },\n",
    "        {\n",
    "            'a_min': 80,\n",
    "            'a_max': 100,\n",
    "            'method': 'min'\n",
    "        },\n",
    "        {\n",
    "            'a_min': 90,\n",
    "            'a_max': 150,\n",
    "            'method': 'max'\n",
    "        },\n",
    "        {\n",
    "            'a_min': 160,\n",
    "            'a_max': 200,\n",
    "            'method': 'max'\n",
    "        },\n",
    "        {\n",
    "            'a_min': 210,\n",
    "            'a_max': 270,\n",
    "            'method': 'max'\n",
    "        },\n",
    "        {\n",
    "            'a_min': 260,\n",
    "            'a_max': 280,\n",
    "            'method': 'min'\n",
    "        },\n",
    "        {\n",
    "            'a_min': 270,\n",
    "            'a_max': 330,\n",
    "            'method': 'max'\n",
    "        }\n",
    "    ]\n",
    "    landmarks = []\n",
    "    rho = 2\n",
    "    centroid = mean(outline_points, axis=0)\n",
    "    \n",
    "    for definition in landmark_definitions:\n",
    "        intersects_for_angles = []\n",
    "        method = np.argmax if definition['method'] == 'max' else np.argmin\n",
    "        \n",
    "        for angle in range(definition['a_min'], definition['a_max']):\n",
    "            startpoint = centroid\n",
    "            endpoint = gh.pol2cart(rho, radians(angle)) + centroid\n",
    "            \n",
    "            intersect = None\n",
    "            for edge in outline_edges:\n",
    "                p1 = outline_points[edge[0], :]\n",
    "                p2 = outline_points[edge[1], :]\n",
    "                \n",
    "                intersect = gh.seg_intersect(p1, p2, startpoint, endpoint)\n",
    "                if intersect is not None:\n",
    "                    break;\n",
    "            if intersect is None:\n",
    "                raise Exception('No Intersect.')\n",
    "            else:\n",
    "                intersects_for_angles.append(intersect)\n",
    "        \n",
    "        intersects_for_angles = np.array(intersects_for_angles)\n",
    "        distances = np.linalg.norm(intersects_for_angles - np.tile(centroid, (intersects_for_angles.shape[0], 1)), axis=1)\n",
    "        \n",
    "        landmarks.append(intersects_for_angles[method(distances), :])\n",
    "        \n",
    "    return np.array(landmarks)\n",
    "\n",
    "def register_outline_with_icp(reference, reference_edges, points, edges, no_iterations = 1):\n",
    "    landmarks_reference = extract_landmark_points(reference, reference_edges)\n",
    "\n",
    "    for i in range(no_iterations):\n",
    "        landmarks = extract_landmark_points(points, edges)\n",
    "        #Compute the transformation between the current source\n",
    "        #and destination cloudpoint\n",
    "        R, t = gh.estimate_rigid_transform(landmarks, landmarks_reference)\n",
    "        R = np.array(R)\n",
    "        t = np.array(t)\n",
    "        #Transform the previous source and update the\n",
    "        #current source cloudpoint\n",
    "        points = (np.dot(R, points.transpose())).transpose() + np.tile(t, (points.shape[0], 1))\n",
    "    \n",
    "    return points\n",
    "\n",
    "def do_registration(files):\n",
    "    loaded = []\n",
    "    transposed_and_scaled = []\n",
    "    registered = []\n",
    "    \n",
    "    for f in files:\n",
    "        tri = np.load(f)\n",
    "        points = tri['points']\n",
    "        triangles = tri['triangles']\n",
    "        \n",
    "        label = os.path.basename(f)\n",
    "        label = ''.join([i if ord(i) < 128 else ' ' for i in label])\n",
    "        \n",
    "        outline_points, outline_edges = gh.extract_outline(points, triangles)\n",
    "        \n",
    "        loaded.append({\n",
    "            'label': label,\n",
    "            'filename': f,\n",
    "            'points': outline_points,\n",
    "            'edges': outline_edges\n",
    "        })\n",
    "    \n",
    "    for outline in loaded:\n",
    "        points = outline['points']\n",
    "        \n",
    "        centroid = mean(points, axis=0)\n",
    "        points = points - np.tile(centroid, (len(points), 1))\n",
    "        \n",
    "        scale = sqrt(np.sum(np.power(points, 2)) / len(points))\n",
    "        points = np.divide(points, scale)\n",
    "        points[: ,0] = -points[:, 0]\n",
    "        points, edges = gh.normalize_outline(points, outline['edges'])\n",
    "        \n",
    "        transposed_and_scaled.append({\n",
    "            'label': outline['label'],\n",
    "            'filename': outline['filename'],\n",
    "            'points': points,\n",
    "            'edges': edges\n",
    "        })\n",
    "    \n",
    "    reference = max(transposed_and_scaled, key=lambda o: o['points'].shape[0])\n",
    "    for outline in transposed_and_scaled:\n",
    "        points = outline['points']\n",
    "        edges = outline['edges']\n",
    "        \n",
    "        if not np.array_equal(points, reference):\n",
    "            points = register_outline_with_icp(reference['points'], reference['edges'], points, outline['edges'])\n",
    "            points, edges = gh.normalize_outline(points, edges)\n",
    "        registered.append({\n",
    "            'label': outline['label'],\n",
    "            'filename': outline['filename'],\n",
    "            'points': points,\n",
    "            'edges': edges\n",
    "        })\n",
    "    \n",
    "    return registered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filenames = glob(DATA_PATH + '*.npz')\n",
    "registered = do_registration(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<matplotlib.figure.Figure at 0x2336bb00>,\n",
       " <matplotlib.axes._subplots.AxesSubplot at 0x24bc5b38>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dh.outlines(plt, registered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x162c3eb8>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outline = registered[20]\n",
    "landmarks = extract_landmark_points(outline['points'], outline['edges'])\n",
    "fig, axes = dh.outline(plt, outline)\n",
    "axes.plot(landmarks[:, 1], landmarks[:, 0], 'bo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for outline in registered:\n",
    "    basename = os.path.basename(outline['filename'])\n",
    "    destination = os.path.join(TO_PATH, basename)\n",
    "    \n",
    "    np.savez(destination, points=outline['points'], edges=outline['edges'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
